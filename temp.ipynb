{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# セル 1: 必要なライブラリのインポート\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Audio, clear_output\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import threading\n",
    "import queue\n",
    "import time\n",
    "import os\n",
    "from loguru import logger\n",
    "import io\n",
    "\n",
    "# fish-speech関連のモジュールをインポート\n",
    "# (fish-speechがインストールされ、パスが通っている必要があります)\n",
    "# 必要に応じて sys.path に fish-speech のパスを追加してください\n",
    "# import sys\n",
    "# sys.path.append('/path/to/fish-speech') # 例\n",
    "try:\n",
    "    from fish_speech.inference_engine import TTSInferenceEngine\n",
    "    from fish_speech.models.text2semantic.inference import launch_thread_safe_queue\n",
    "    from fish_speech.models.vqgan.inference import load_model as load_decoder_model\n",
    "    from fish_speech.utils.schema import ServeTTSRequest\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing fish-speech modules: {e}\")\n",
    "    print(\"Please ensure fish-speech is installed and accessible in your Python path.\")\n",
    "    # ここで処理を中断するか、ダミーの関数を定義するなどの対応が必要です\n",
    "    raise e\n",
    "\n",
    "print(\"必要なライブラリをインポートしました。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# セル 2: 設定値 (モデルパスなどを環境に合わせて変更してください)\n",
    "\n",
    "# --- ユーザー設定 ---\n",
    "LLAMA_CHECKPOINT_PATH = Path(\"./checkpoints/fish-speech-1.5\") # LLAMAモデルのパス\n",
    "DECODER_CHECKPOINT_PATH = Path(\"./checkpoints/fish-speech-1.5/firefly-gan-vq-fsq-8x1024-21hz-generator.pth\") # VQGANモデルのパス\n",
    "DECODER_CONFIG_NAME = \"firefly_gan_vq\" # VQGANモデルの設定名\n",
    "# --------------------\n",
    "\n",
    "# デバイス設定 (自動検出)\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "    PRECISION = torch.bfloat16 # または torch.float16\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = \"mps\"\n",
    "    PRECISION = torch.float16 # MPSはbfloat16をサポートしない場合がある\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "    PRECISION = torch.float32\n",
    "\n",
    "COMPILE_MODEL = True # モデルコンパイルを有効にするか (高速化のため推奨)\n",
    "\n",
    "# WindowsかつCompile=Trueの場合、警告を出す (動作しない可能性があるため)\n",
    "if os.name == 'nt' and COMPILE_MODEL:\n",
    "    print(\"警告: Windows環境でのモデルコンパイルは不安定な場合があります。エラーが発生する場合は COMPILE_MODEL = False を試してください。\")\n",
    "\n",
    "# Make einx happy (fish-speechが必要とする可能性あり)\n",
    "os.environ[\"EINX_FILTER_TRACEBACK\"] = \"false\"\n",
    "\n",
    "print(f\"デバイス: {DEVICE}\")\n",
    "print(f\"精度: {PRECISION}\")\n",
    "print(f\"モデルコンパイル: {COMPILE_MODEL}\")\n",
    "print(f\"LLAMAモデルパス: {LLAMA_CHECKPOINT_PATH}\")\n",
    "print(f\"VQGANモデルパス: {DECODER_CHECKPOINT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# セル 3: モデルの読み込みとコンパイル (ログ出力修正)\n",
    "\n",
    "# ★ ログ表示用のOutputウィジェットを先に定義 (セル4の前に移動しても良い)\n",
    "log_output = widgets.Output(layout=widgets.Layout(height='100px', border='1px solid gray', overflow_y='scroll'))\n",
    "\n",
    "# ★ ログメッセージを出力する関数\n",
    "def log_message(msg, level=\"info\"):\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    with log_output:\n",
    "        if level == \"error\":\n",
    "            print(f\"<font color='red'>[{timestamp}] ERROR: {msg}</font>\")\n",
    "        else:\n",
    "            print(f\"[{timestamp}] INFO: {msg}\")\n",
    "\n",
    "# --- モデル読み込み処理 ---\n",
    "log_message(\"モデルの読み込みとコンパイルを開始します。時間がかかる場合があります...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# 1. LLAMAモデルを別スレッドで読み込み&コンパイル\n",
    "try:\n",
    "    log_message(\"LLAMAモデルを読み込んでいます...\")\n",
    "    llama_queue = launch_thread_safe_queue(\n",
    "        checkpoint_path=LLAMA_CHECKPOINT_PATH,\n",
    "        device=DEVICE,\n",
    "        precision=PRECISION,\n",
    "        compile=COMPILE_MODEL,\n",
    "    )\n",
    "    log_message(\"LLAMAモデルの読み込み完了。\")\n",
    "except Exception as e:\n",
    "    log_message(f\"LLAMAモデルの読み込み中にエラーが発生しました: {e}\", level=\"error\")\n",
    "    if COMPILE_MODEL:\n",
    "        log_message(\"コンパイルなしで再試行します (COMPILE_MODEL = False)...\")\n",
    "        COMPILE_MODEL = False\n",
    "        llama_queue = launch_thread_safe_queue(\n",
    "            checkpoint_path=LLAMA_CHECKPOINT_PATH,\n",
    "            device=DEVICE,\n",
    "            precision=PRECISION,\n",
    "            compile=COMPILE_MODEL,\n",
    "        )\n",
    "        log_message(\"LLAMAモデルの読み込み完了 (コンパイルなし)。\")\n",
    "    else:\n",
    "        raise e\n",
    "\n",
    "# 2. VQGANデコーダーモデルの読み込み\n",
    "log_message(\"VQGANデコーダーモデルを読み込んでいます...\")\n",
    "decoder_model = load_decoder_model(\n",
    "    config_name=DECODER_CONFIG_NAME,\n",
    "    checkpoint_path=DECODER_CHECKPOINT_PATH,\n",
    "    device=DEVICE,\n",
    ")\n",
    "log_message(\"VQGANデコーダーモデルの読み込み完了。\")\n",
    "\n",
    "# 3. TTS推論エンジンの初期化\n",
    "log_message(\"TTS推論エンジンを初期化しています...\")\n",
    "inference_engine = TTSInferenceEngine(\n",
    "    llama_queue=llama_queue,\n",
    "    decoder_model=decoder_model,\n",
    "    compile=COMPILE_MODEL,\n",
    "    precision=PRECISION,\n",
    ")\n",
    "log_message(\"TTS推論エンジンの初期化完了。\")\n",
    "\n",
    "# 4. ウォームアップ実行\n",
    "log_message(\"モデルのウォームアップを実行中...\")\n",
    "try:\n",
    "    # ウォームアップのリクエストを少し調整\n",
    "    warmup_req = ServeTTSRequest(text=\"音声合成エンジンのウォームアップ中です。\")\n",
    "    _ = list(inference_engine.inference(warmup_req))\n",
    "    log_message(\"ウォームアップ完了。\")\n",
    "except Exception as e:\n",
    "    log_message(f\"ウォームアップ中にエラーが発生しました: {e}\", level=\"error\")\n",
    "    log_message(\"アプリは起動しますが、初回の音声生成に時間がかかる可能性があります。\")\n",
    "\n",
    "end_time = time.time()\n",
    "log_message(f\"モデルの準備完了。所要時間: {end_time - start_time:.2f} 秒\")\n",
    "\n",
    "# グローバル変数としてエンジンを保持\n",
    "tts_engine_global = inference_engine\n",
    "\n",
    "# ★ セル3の最後にログ出力エリアを表示\n",
    "display(log_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# セル 4: ipywidgets UIの定義と表示 (ログエリア追加)\n",
    "\n",
    "# --- UI要素の定義 ---\n",
    "app_title = widgets.HTML(\"<h1>GMC Speech</h1>\")\n",
    "text_input = widgets.Textarea(\n",
    "    placeholder='ここにテキストを入力するか、下のボタンからファイルをアップロードして内容を編集してください。',\n",
    "    layout=widgets.Layout(width='95%', height='150px')\n",
    ")\n",
    "file_upload = widgets.FileUpload(\n",
    "    accept='.txt',\n",
    "    multiple=False,\n",
    "    description='テキスト読込(&編集)',\n",
    "    tooltip='テキストファイルを読み込み、テキストエリアに表示して編集できます'\n",
    ")\n",
    "generate_button = widgets.Button(\n",
    "    description='音声生成',\n",
    "    button_style='success',\n",
    "    tooltip='入力/編集されたテキストから音声を生成します',\n",
    "    icon='play',\n",
    "    layout=widgets.Layout(width='auto')\n",
    ")\n",
    "status_label = widgets.Label(value=\"準備完了\") # 初期ステータス\n",
    "audio_output = widgets.Output()\n",
    "\n",
    "# --- UIレイアウト ---\n",
    "ui_layout = widgets.VBox([\n",
    "    app_title,\n",
    "    text_input,\n",
    "    widgets.HBox([file_upload, generate_button]),\n",
    "    status_label,\n",
    "    audio_output,\n",
    "    widgets.HTML(\"<hr><b>ログ:</b>\"), # ログエリアの区切り線とタイトル\n",
    "    log_output # ★ ログ表示エリアをレイアウトに追加\n",
    "])\n",
    "\n",
    "# --- UI表示 ---\n",
    "display(ui_layout)\n",
    "\n",
    "# log_message(\"UIを表示しました。\") # log_outputはセル3の最後で表示されるため、ここでは不要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# セル 5: イベントハンドラの定義 (ファイル読込、完了表示タイミング、ログ修正)\n",
    "\n",
    "# ファイルアップロード時の処理 (修正版)\n",
    "def on_file_upload_change(change):\n",
    "    # `change['new']` は現在のウィジェットの値 (ファイルのタプル)\n",
    "    # `change['old']` は変更前の値\n",
    "    uploaded_files_tuple = change['new']\n",
    "    if uploaded_files_tuple: # タプルが空でなければファイルが選択された\n",
    "        uploaded_file_info = uploaded_files_tuple[0] # 最初のファイルを取得\n",
    "        file_name = uploaded_file_info['name']\n",
    "        file_content = uploaded_file_info['content'] # これは memoryview または bytes\n",
    "\n",
    "        log_message(f\"ファイル '{file_name}' が選択されました。読み込み中...\")\n",
    "        try:\n",
    "            # content が memoryview の場合は bytes に変換\n",
    "            if isinstance(file_content, memoryview):\n",
    "                content_bytes = file_content.tobytes()\n",
    "            else:\n",
    "                content_bytes = file_content\n",
    "\n",
    "            # UTF-8でデコードを試みる\n",
    "            content = content_bytes.decode('utf-8')\n",
    "            text_input.value = content # テキストエリアに設定\n",
    "            status_label.value = f\"ファイル '{file_name}' を読み込みました。内容は編集可能です。\"\n",
    "            log_message(f\"ファイル '{file_name}' の内容をテキストエリアに表示しました。\")\n",
    "        except UnicodeDecodeError:\n",
    "            # 他のエンコーディング (Shift_JISなど) で試す場合\n",
    "            try:\n",
    "                log_message(\"UTF-8でのデコードに失敗、Shift_JISで再試行...\")\n",
    "                content = content_bytes.decode('shift_jis')\n",
    "                text_input.value = content\n",
    "                status_label.value = f\"ファイル '{file_name}' を読み込みました(Shift_JIS)。内容は編集可能です。\"\n",
    "                log_message(f\"ファイル '{file_name}' の内容をテキストエリアに表示しました(Shift_JIS)。\")\n",
    "            except Exception as e:\n",
    "                status_label.value = f\"ファイルの読み込み/デコードに失敗しました: {e}\"\n",
    "                log_message(f\"ファイルの読み込み/デコードに失敗しました: {file_name}, Error: {e}\", level=\"error\")\n",
    "        except Exception as e:\n",
    "            status_label.value = f\"ファイルの処理中にエラーが発生しました: {e}\"\n",
    "            log_message(f\"ファイルの処理中にエラーが発生しました: {file_name}, Error: {e}\", level=\"error\")\n",
    "        finally:\n",
    "            # ★ アップロードウィジェットの値をクリア (コールバック内で値を変更して再度トリガーさせないように注意)\n",
    "            #   None を設定するとリセットされることが多い\n",
    "            if file_upload.value is not None:\n",
    "                # イベントループの問題を避けるため、直接Noneを代入\n",
    "                file_upload.value = None\n",
    "                # widgetの値を直接変更した場合、observeが再度呼ばれる可能性があるため注意\n",
    "                # 次回のアップロードのためにクリアするだけならこれでOKな場合が多い\n",
    "\n",
    "    # ファイル選択がキャンセルされた場合やクリアされた場合 (タプルが空になる)\n",
    "    # else:\n",
    "    #    log_message(\"ファイル選択がキャンセルされました。\")\n",
    "    #    pass\n",
    "\n",
    "# 音声生成ボタンクリック時の処理 (完了表示タイミング、ログ修正)\n",
    "def on_generate_button_clicked(b):\n",
    "    # 既存の音声出力をクリア\n",
    "    with audio_output:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    input_text = text_input.value.strip()\n",
    "    if not input_text:\n",
    "        status_label.value = \"テキストが入力されていません。\"\n",
    "        log_message(\"音声生成をスキップ: テキスト未入力\", level=\"error\")\n",
    "        return\n",
    "\n",
    "    # ボタンを無効化し、ステータスを更新\n",
    "    generate_button.disabled = True\n",
    "    status_label.value = \"音声生成中... (テキストの長さによっては時間がかかります)\"\n",
    "    log_message(f\"音声生成開始: テキスト長={len(input_text)}\")\n",
    "\n",
    "    try:\n",
    "        start_gen_time = time.time()\n",
    "\n",
    "        # TTS推論リクエストを作成\n",
    "        req = ServeTTSRequest(text=input_text)\n",
    "\n",
    "        # グローバル変数から推論エンジンを取得\n",
    "        engine = tts_engine_global\n",
    "\n",
    "        # 音声生成を実行\n",
    "        generated_audio_data = None\n",
    "        sample_rate = 44100\n",
    "\n",
    "        log_message(\"推論エンジン呼び出し中...\")\n",
    "        for result in engine.inference(req):\n",
    "            if result.code == \"final\" and result.audio is not None:\n",
    "                log_message(\"推論エンジンから最終音声データ受信。\")\n",
    "                sample_rate, generated_audio_data = result.audio\n",
    "                break\n",
    "            elif result.code == \"error\":\n",
    "                log_message(f\"推論中にエラー発生: {result.error}\", level=\"error\")\n",
    "                raise result.error\n",
    "            elif result.code == \"header\":\n",
    "                log_message(\"音声ストリームヘッダー受信。\")\n",
    "            elif result.code == \"segment\":\n",
    "                log_message(\"音声セグメント受信。\") # ストリーミングしない場合は通常通らない\n",
    "\n",
    "        end_gen_time = time.time()\n",
    "        gen_duration = end_gen_time - start_gen_time\n",
    "        log_message(f\"推論エンジン処理完了。({gen_duration:.2f} 秒)\")\n",
    "\n",
    "        if generated_audio_data is not None:\n",
    "            # ★ 音声データをIPython.display.Audioで表示\n",
    "            log_message(\"音声プレーヤーを表示します...\")\n",
    "            with audio_output:\n",
    "                display(Audio(data=generated_audio_data, rate=sample_rate))\n",
    "            # ★ 音声表示後にステータスを更新\n",
    "            status_label.value = f\"音声生成完了！ ({gen_duration:.2f} 秒)\"\n",
    "            log_message(f\"音声生成完了。再生時間: {len(generated_audio_data)/sample_rate:.2f}秒\")\n",
    "        else:\n",
    "            status_label.value = \"音声の生成に失敗しました（データがありません）。\"\n",
    "            log_message(\"音声生成失敗: 推論エンジンからデータが返されませんでした。\", level=\"error\")\n",
    "\n",
    "    except Exception as e:\n",
    "        status_label.value = f\"エラーが発生しました: {e}\"\n",
    "        log_message(f\"音声生成中に予期せぬエラー: {e}\", level=\"error\")\n",
    "        import traceback\n",
    "        log_message(traceback.format_exc(), level=\"error\") # 詳細なトレースバックをログへ\n",
    "\n",
    "    finally:\n",
    "        # ボタンを再度有効化\n",
    "        generate_button.disabled = False\n",
    "        log_message(\"音声生成ボタンを有効化しました。\")\n",
    "\n",
    "# log_message(\"イベントハンドラを定義しました。\") # log_outputはセル3の最後で表示されるため、ここでは不要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# セル 6: イベントハンドラとウィジェットの連携設定\n",
    "\n",
    "# FileUploadウィジェットの値が変更されたらon_file_upload_changeを呼び出す\n",
    "file_upload.observe(on_file_upload_change, names='value')\n",
    "\n",
    "# Buttonウィジェットがクリックされたらon_generate_button_clickedを呼び出す\n",
    "generate_button.on_click(on_generate_button_clicked)\n",
    "\n",
    "print(\"イベントハンドラを設定しました。アプリを使用できます。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}